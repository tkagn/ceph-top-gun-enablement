<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Untitled :: Ceph Top Gun Enablement</title>
    <link rel="canonical" href="https://likid0.github.io/ceph-top-gun-enablement/training/ceph/ceph-object-store-tool.html">
    <meta name="generator" content="Antora 3.0.1">
    <link rel="stylesheet" href="../../_/css/site.css">
    <script>var uiRootPath = '../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage" target="_blank">
          <img src="../../_/img/header_logo_reverse.svg" height="40px" alt="Red Hat Data Services">
      </a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Get Help</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_container_storage" target="_blank">OCS Documentation</a>
            <a class="navbar-item" href="https://bugzilla.redhat.com/describecomponents.cgi?product=Red%20Hat%20OpenShift%20Container%20Storage" target="_blank">Browse Bugs</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Improve Guides</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/red-hat-storage/ocs-training/blob/master/CONTRIBUTING.adoc" target="_blank">Guidelines</a>
            <a class="navbar-item" href="https://github.com/red-hat-storage/ocs-training/issues/new/choose" target="_blank">Open Issue</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">More Infos</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://www.redhat.com/en/blog/channel/red-hat-storage" target="_blank">Our Blog</a>
            <a class="navbar-item" href="https://www.youtube.com/channel/UCoyG8VyvB-XUxQl1mD3T3Gw" target="_blank">Youtube</a>
            <a class="navbar-item" href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage" target="_blank">OCS Technology</a>
          </div>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="training" data-version="master">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Ceph Top-Gun Enablement</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="opentlc_lab_env.html">Opentlc Lab Env</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph RadosGW</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_intro.html">RGW Introduction and Deployment</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_arch_deep_dive.html">RGW Deep Dive</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_ha.html">RGW High Availability</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_users_quotas.html">RGW Users &amp; Quotas</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_auth.html">RGW Auth &amp; Authz</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_object_versioning.html">RGW S3 Object Versioning</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_placement_and_storage_classes.html">RGW Placement &amp; Storage Classes</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_life_cycle_management.html">RGW Life Cycle Management</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_bucket_policy.html">RGW S3 Bucket Policy</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_sts_introduction.html">RGW Secure Token Service</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_sts_bucket_role_policy.html">RGW Bucket vs Role Policy</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_multisite.html">RGW Multisite Replication</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Troubleshooting</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="trouble-shooting-nearfull-osds.html">Troubleshooting nearfull OSDs</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="radosgw_multisite.html">RGW Multisite Replication</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Ceph Stretched</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="rhcs-stretched-deploy.html">Ceph Stretch Mode</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Ceph Top-Gun Enablement</span>
    <span class="version">master</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Ceph Top-Gun Enablement</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">master</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
</nav>
  <div class="edit-this-page"><a href="file:///antora/training/modules/ceph/pages/ceph-object-store-tool.adoc">Edit this Page</a></div>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<div class="sect1">
<h2 id="_internal_bluestore_tools_in_ceph_containers"><a class="anchor" href="#_internal_bluestore_tools_in_ceph_containers"></a>Internal bluestore tools in Ceph containers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When troubleshooting Ceph, sometimes we need to use some tools such as
<code>ceph-objectstore-tool</code> or <code>ceph-bluestore-tool</code>. When working in
containerized environments this is more complicated as there are a set
of internal scripts inside the container that automatically start the
OSD service and the OSD is automatically included in the cluster upon
start.</p>
</div>
<div class="paragraph">
<p>We have received a procedure from
<a href="https://access.redhat.com/support/cases/#/case/02801980">Red Hat Support</a>
where there is no need to modify the official RHCS image.</p>
</div>
<div class="paragraph">
<p><strong>1. Set <code>noout</code> flag on Ceph cluster</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ podman exec ceph-mon-$(hostname -s) ceph osd set noout
noout is set</pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Login to the node hosting the OSD container</strong></p>
</div>
<div class="paragraph">
<p>In our case we are going to act in the node <code>ceph1</code> and the <code>osd.0</code>:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ podman exec ceph-mon-$(hostname -s) ceph osd tree
ID CLASS WEIGHT  TYPE NAME      STATUS REWEIGHT PRI-AFF
-1       0.17578 root default
-5       0.05859     host ceph1
 0   hdd 0.02930         osd.0      up  1.00000 1.00000
 4   hdd 0.02930         osd.4      up  1.00000 1.00000
-7       0.05859     host ceph2
 1   hdd 0.02930         osd.1      up  1.00000 1.00000
 3   hdd 0.02930         osd.3      up  1.00000 1.00000
-3       0.05859     host ceph3
 2   hdd 0.02930         osd.2      up  1.00000 1.00000
 5   hdd 0.02930         osd.5      up  1.00000 1.00000</pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Backup <code>/etc/systemd/system/ceph-osd@.service</code> unit file to <code>/root</code>
directory</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ cp /etc/systemd/system/ceph-osd@.service /root/ceph-osd@.service.backup</pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Move <code>/run/ceph-osd@osd_id.service-cid</code> file to <code>/root</code></strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ mv /run/ceph-osd@0.service-cid /root</pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Edit <code>/etc/systemd/system/ceph-osd@.service</code> unit file</strong></p>
</div>
<div class="paragraph">
<p>Add <code>-it --entrypoint /bin/bash</code> option to podman command.</p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ vim /etc/systemd/system/ceph-osd@.service
# Please do not change this file directly since it is managed by Ansible and will be overwritten
[Unit]
Description=Ceph OSD
After=network.target

[Service]
EnvironmentFile=-/etc/environment
ExecStartPre=-/usr/bin/rm -f /%t/%n-pid /%t/%n-cid
ExecStartPre=-/usr/bin/podman rm -f ceph-osd-%i
&lt;ExecStart=/usr/bin/podman run \
&gt;ExecStart=/usr/bin/podman run -it --entrypoint /bin/bash \
  -d --conmon-pidfile /%t/%n-pid --cidfile /%t/%n-cid \
  --rm \
  --net=host \
  --privileged=true \
  --pid=host \
  --ipc=host \
  --cpus=4 \
  -v /dev:/dev \
  -v /etc/localtime:/etc/localtime:ro \
  -v /var/lib/ceph:/var/lib/ceph:z \
  -v /etc/ceph:/etc/ceph:z \
  -v /var/run/ceph:/var/run/ceph:z \
  -v /var/run/udev/:/var/run/udev/ \
  -v /var/log/ceph:/var/log/ceph:z \
  -e OSD_BLUESTORE=1 -e OSD_FILESTORE=0 -e OSD_DMCRYPT=0 \
  -e CLUSTER=ceph \
  -v /run/lvm/:/run/lvm/ \
  -e CEPH_DAEMON=OSD_CEPH_VOLUME_ACTIVATE \
  -e CONTAINER_IMAGE=bastion:5000/rhceph/rhceph-4-rhel8:latest \
  -e OSD_ID=%i \
&gt;  -e DEBUG=stayalive \
  --name=ceph-osd-%i \
  --log-opt=path="/dev/null" \
  bastion:5000/rhceph/rhceph-4-rhel8:latest
ExecStop=-/usr/bin/sh -c "/usr/bin/podman rm -f `cat /%t/%n-cid`"
KillMode=none
Restart=always
RestartSec=10s
TimeoutStartSec=120
TimeoutStopSec=15
Type=forking
PIDFile=/%t/%n-pid

[Install]
WantedBy=multi-user.target</pre>
</div>
</div>
<div class="paragraph">
<p><strong>6. Reload systemd manager configuration</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ systemctl daemon-reload</pre>
</div>
</div>
<div class="paragraph">
<p><strong>7. Re-start the OSD service associated with our OSD</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ systemctl restart ceph-osd@0.service</pre>
</div>
</div>
<div class="paragraph">
<p><strong>8. Login to container associated with our OSD</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$  podman exec -it ceph-osd-0 /bin/bash</pre>
</div>
</div>
<div class="paragraph">
<p><strong>9. Get osd fsid and activate the OSD to mount OSD LV</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ osd_fsid=$(ceph-volume lvm list |grep -A15 "osd\.0"|grep "osd fsid" | awk '{print $3}')
$ echo $osd_fsid
8a398b35-aa13-4363-9652-e2aa6dd1fb8d
$ ceph-volume lvm activate --bluestore 0 $osd_fsid
Running command: /usr/bin/mount -t tmpfs tmpfs /var/lib/ceph/osd/ceph-0
Running command: /usr/bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0
Running command: /usr/bin/ceph-bluestore-tool --cluster=ceph prime-osd-dir --dev /dev/ceph-a54942f0-a335-4a5f-9028-27825e779605/osd-data-a4a8734e-0222-4c7c-933e-73da01938c59 --path /var/lib/ceph/osd/ceph-0 --no-mon-config
Running command: /usr/bin/ln -snf /dev/ceph-a54942f0-a335-4a5f-9028-27825e779605/osd-data-a4a8734e-0222-4c7c-933e-73da01938c59 /var/lib/ceph/osd/ceph-0/block
Running command: /usr/bin/chown -h ceph:ceph /var/lib/ceph/osd/ceph-0/block
Running command: /usr/bin/chown -R ceph:ceph /dev/dm-0
Running command: /usr/bin/chown -R ceph:ceph /var/lib/ceph/osd/ceph-0
Running command: /usr/bin/systemctl enable ceph-volume@lvm-0-8a398b35-aa13-4363-9652-e2aa6dd1fb8d
 stderr: Created symlink /etc/systemd/system/multi-user.target.wants/ceph-volume@lvm-0-8a398b35-aa13-4363-9652-e2aa6dd1fb8d.service → /usr/lib/systemd/system/ceph-volume@.service.
Running command: /usr/bin/systemctl enable --runtime ceph-osd@0
 stderr: Created symlink /run/systemd/system/ceph-osd.target.wants/ceph-osd@0.service → /usr/lib/systemd/system/ceph-osd@.service.
Running command: /usr/bin/systemctl start ceph-osd@0
 stderr: Running in chroot, ignoring request: start
--&gt; ceph-volume lvm activate successful for osd ID: 0</pre>
</div>
</div>
<div class="paragraph">
<p><strong>10. Run <code>ceph-objectstore-tool</code> or <code>ceph-bluestore-tool</code> commands</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-0 --op list
$ ceph-bluestore-tool show-label --dev /dev/ceph-a54942f0-a335-4a5f-9028-27825e779605/osd-data-a4a8734e-0222-4c7c-933e-73da01938c59
{
    "/dev/ceph-a54942f0-a335-4a5f-9028-27825e779605/osd-data-a4a8734e-0222-4c7c-933e-73da01938c59": {
        "osd_uuid": "8a398b35-aa13-4363-9652-e2aa6dd1fb8d",
        "size": 32208060416,
        "btime": "2021-01-25 07:02:17.277679",
        "description": "main",
        "bluefs": "1",
        "ceph_fsid": "d8a34408-3b5a-4ee3-bd12-b32f6f466c60",
        "kv_backend": "rocksdb",
        "magic": "ceph osd volume v026",
        "mkfs_done": "yes",
        "osd_key": "AQBHsw5glhbhNhAAXGDN2BdMkXan71OFduMrRA==",
        "ready": "ready",
        "require_osd_release": "14",
        "whoami": "0"
    }
}
$ exit</pre>
</div>
</div>
<div class="sect2">
<h3 id="_restore_steps"><a class="anchor" href="#_restore_steps"></a>Restore steps</h3>
<div class="paragraph">
<p><strong>1. Copy <code>/etc/systemd/system/ceph-osd@.service</code> unit file from <code>/root</code>
directory</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ cp /etc/systemd/system/ceph-osd@.service /root/ceph-osd@.service.modified
$ cp /root/ceph-osd@.service.backup /etc/systemd/system/ceph-osd@.service</pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Reload systemd manager configuration</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ systemctl daemon-reload</pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Move <code>/run/ceph-osd@osd_id.service-cid</code> file to <code>/tmp</code> and restart
the OSD service associated with our OSD</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ mv /run/ceph-osd@0.service-cid /tmp
$ systemctl restart ceph-osd@0.service</pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Unset <code>noout</code> flag on Ceph cluster</strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ podman exec ceph-mon-$(hostname -s) ceph osd unset noout
noout is unset</pre>
</div>
</div>
<div class="paragraph">
<p><strong>5. Ensure Ceph status is in <code>HEALTH_OK</code></strong></p>
</div>
<div class="literalblock">
<div class="content">
<pre>$ podman exec ceph-mon-$(hostname -s) ceph -s
  cluster:
    id:     d8a34408-3b5a-4ee3-bd12-b32f6f466c60
    health: HEALTH_OK

  services:
    mon: 3 daemons, quorum ceph1,ceph2,ceph3 (age 27h)
    mgr: ceph2(active, since 27h), standbys: ceph1, ceph3
    osd: 6 osds: 6 up (since 80s), 6 in (since 80s)
    rgw: 3 daemons active (ceph1.rgw0, ceph2.rgw0, ceph3.rgw0)

  task status:

  data:
    pools:   18 pools, 264 pgs
    objects: 1.24k objects, 56 KiB
    usage:   6.4 GiB used, 174 GiB / 180 GiB avail
    pgs:     264 active+clean

  io:
    client:   341 B/s rd, 0 op/s rd, 0 op/s wr</pre>
</div>
</div>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <a class="navbar-item" href="https://www.redhat.com/en/technologies/cloud-computing/openshift-container-storage" target="_blank">
      <img src="../../_/img/header_logo.svg" alt="Red Hat Data Services">
  </a>
</footer>
<script id="site-script" src="../../_/js/site.js" data-ui-root-path="../../_"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
  </body>
</html>
